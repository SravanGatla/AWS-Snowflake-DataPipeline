{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPpY1E1rdSlCZfzbO/DV4K5",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SravanGatla/AWS-Snowflake-DataPipeline/blob/main/testing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-woVEKcbtzs8"
      },
      "outputs": [],
      "source": [
        "import boto3\n",
        "import pandas as pd\n",
        "\n",
        "class S3Fetcher:\n",
        "    @staticmethod\n",
        "    def fetch_csv_data(bucket_name, file_key):\n",
        "        s3 = boto3.client('s3')\n",
        "        response = s3.get_object(Bucket=bucket_name, Key=file_key)\n",
        "        content = response['Body'].read().decode('utf-8')\n",
        "        return pd.read_csv(pd.compat.StringIO(content))\n",
        "\n",
        "    @staticmethod\n",
        "    def fetch_json_data(bucket_name, file_key):\n",
        "        s3 = boto3.client('s3')\n",
        "        response = s3.get_object(Bucket=bucket_name, Key=file_key)\n",
        "        content = response['Body'].read().decode('utf-8')\n",
        "        return pd.read_json(pd.compat.StringIO(content))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pytest\n",
        "from your_module import CSVDataExtractor\n",
        "from S3Fetcher import S3Fetcher\n",
        "\n",
        "class TestCSVDataExtractor:\n",
        "    @pytest.fixture\n",
        "    def example_csv_data(self):\n",
        "        return S3Fetcher.fetch_csv_data('your-test-bucket-name', 'test-file.csv')\n",
        "\n",
        "    def test_extract_data(self, example_csv_data):\n",
        "        extractor = CSVDataExtractor('test-bucket', 'test-file.csv')\n",
        "        result = extractor.extract_data()\n",
        "\n",
        "        assert len(result) == 1\n",
        "        assert result[0].equals(example_csv_data)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    pytest.main()\n"
      ],
      "metadata": {
        "id": "mZ4QKSh8wZKf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pytest\n",
        "from your_module import JSONDataExtractor\n",
        "from S3Fetcher import S3Fetcher\n",
        "\n",
        "class TestJSONDataExtractor:\n",
        "    @pytest.fixture\n",
        "    def example_json_data(self):\n",
        "        return S3Fetcher.fetch_json_data('your-test-bucket-name', 'test-file.json')\n",
        "\n",
        "    def test_extract_data(self, example_json_data):\n",
        "        extractor = JSONDataExtractor('test-bucket', 'test-file.json')\n",
        "        result = extractor.extract_data()\n",
        "\n",
        "        assert len(result) == 1\n",
        "        assert result[0].equals(example_json_data)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    pytest.main()\n",
        ""
      ],
      "metadata": {
        "id": "29iNsImpwRqt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pytest\n",
        "from your_module import DataProcessor\n",
        "from S3Fetcher import S3Fetcher\n",
        "\n",
        "class TestDataProcessor:\n",
        "    @pytest.fixture\n",
        "    def example_data(self):\n",
        "        return S3Fetcher.fetch_csv_data('your-test-bucket-name', 'test-file.csv')\n",
        "\n",
        "    def test_process_and_analyze_data(self, example_data):\n",
        "        processor = DataProcessor(example_data)\n",
        "        result = processor.process_and_analyze_data()\n",
        "\n",
        "        assert result['age'].dtype == int\n",
        "        assert result['date'].dtype == 'datetime64[ns]'\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    pytest.main()\n"
      ],
      "metadata": {
        "id": "xLZUUkco2g_L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pytest\n",
        "from your_module import DataMasker\n",
        "from S3Fetcher import S3Fetcher\n",
        "\n",
        "class TestDataMasker:\n",
        "    @pytest.fixture\n",
        "    def example_data(self):\n",
        "        return S3Fetcher.fetch_csv_data('your-test-bucket-name', 'test-file.csv')\n",
        "\n",
        "    def test_mask_sensitive_data(self, example_data):\n",
        "        masker = DataMasker([example_data])\n",
        "        result = masker.mask_sensitive_data()\n",
        "\n",
        "        assert len(result) == 1\n",
        "        assert result[0].equals(example_data)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    pytest.main()\n"
      ],
      "metadata": {
        "id": "090FqhBz2hOd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pytest\n",
        "from your_module import SnowflakeLoader\n",
        "from S3Fetcher import S3Fetcher\n",
        "from unittest.mock import patch, MagicMock\n",
        "\n",
        "class TestSnowflakeLoader:\n",
        "    @pytest.fixture\n",
        "    def example_data(self):\n",
        "        return S3Fetcher.fetch_csv_data('your-test-bucket-name', 'test-file.csv')\n",
        "\n",
        "    @patch('snowflake.connector.connect')\n",
        "    def test_load_data_to_snowflake(self, mock_connect, example_data):\n",
        "        mock_cursor = MagicMock()\n",
        "        mock_connect.return_value.cursor.return_value = mock_cursor\n",
        "\n",
        "        loader = SnowflakeLoader([example_data], {}, 'test_table')\n",
        "        loader.load_data_to_snowflake()\n",
        "\n",
        "        assert mock_cursor.execute.called\n",
        "        assert mock_cursor.commit.called\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    pytest.main()\n"
      ],
      "metadata": {
        "id": "JAgsM0k-2hW5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pytest\n",
        "from your_module import DataProcessor, DataMasker, SnowflakeLoader\n",
        "from S3Fetcher import S3Fetcher\n",
        "from unittest.mock import patch\n",
        "\n",
        "class TestParallelProcessing:\n",
        "    @pytest.fixture\n",
        "    def example_data(self):\n",
        "        return S3Fetcher.fetch_csv_data('your-test-bucket-name', 'test-file.csv')\n",
        "\n",
        "    def test_process_data_in_parallel(self, example_data):\n",
        "        processor = DataProcessor(example_data)\n",
        "        result = processor.process_data_in_parallel()\n",
        "        assert result['age'].dtype == int\n",
        "        assert result['date'].dtype == 'datetime64[ns]'\n",
        "\n",
        "    def test_mask_data_in_parallel(self, example_data):\n",
        "        masker = DataMasker([example_data])\n",
        "        result = masker.mask_data_in_parallel()\n",
        "        assert len(result) == 1\n",
        "        assert result[0].equals(example_data)\n",
        "\n",
        "    @patch('snowflake.connector.connect')\n",
        "    def test_load_data_in_parallel(self, mock_connect, example_data):\n",
        "        mock_cursor = MagicMock()\n",
        "        mock_connect.return_value.cursor.return_value = mock_cursor\n",
        "\n",
        "        loader = SnowflakeLoader([example_data], {}, 'test_table')\n",
        "        loader.load_data_in_parallel()\n",
        "\n",
        "        assert mock_cursor.execute.called\n",
        "        assert mock_cursor.commit.called\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    pytest.main()\n"
      ],
      "metadata": {
        "id": "KqJnMTaKBmEw"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}